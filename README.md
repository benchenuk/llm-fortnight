# LLM Fortnight
This is a space for keeping releveant notes and documents produdced along the way of testing and using different locally deployed LLMs. 

## Models
A handful of models are just small enough to run on consumer computers to allow exploring and testing latest LLM capabilities. 
The open source community continues releasing more and more powerful and speedy models. I'd say these models are not only fit for prototyping locally, with careful selection and configuration, also competent for basic assistive tasks.       

- DeepSeek R1
- Qwen2.5 Coder
- Qwen2.5 14B 1M
- QwQ 32B
- Phi4-Mini
- Gemma 3

## Stack
- Copilot
- Gemini Code Assist
- CodeGPT
- Roo Code
- VS Code
- Searxng
- Open WebUI
- LM Studio
- Ollama
- 32G RAM
- Apple Silicon M4

## Prompts
Not that long before "vibe doing" things became trendy, there was proper term for it - "prompt engineering". 
It is a technique for engineer-minded user to instruct LLM exactly the way you want it respond. 
It makes noticeable and substantial differences to the quality of chat outputs, given the same capability of the model under test. 

Like the publicly available benchmarks, for every new (version) of model, a same set of questions are sent to the model to "vibe check" the performance and character of the model. 

And then this process will repeat with every parameter or system prompt change, until a satisfactory combination is found.  


## Leader Board